# ﻿Helper functions 

## dataFromQuandl (int Handle, string Format, string Code, int Column): var 

Helper function for generating an indicator based on a Quandl™ EOD time series. Works in live trading as well as in backtest mode, and returns the content of the field **Column** from the dataset **Code** in the given **Format**. This function is often used for getting extra market data, such as the yield rate or the Commitment of Traders (COT) report of particular assets. Timestamps are automatically adjusted by 16 hours so that the indicator changes when the US market opens. If this is not desired, remove the term **-16./24** from the function source code in **contract.c** (which must be included for using this function). **Zorro S** is required for accessing Quandl data. 

## dataFromCSV (int Handle, string Format, string Filename, int Column,int Offset): var 

Helper function for generating an indicator based on a downloaded CSV file; for backtesting only. Returns the content of the field **Column** from the 

file **Filename.csv** in the given **Format**. **Offset** is the time stamp adjustment in minutes, f.i. to 16:00 for avoiding future peeking with EOD data. Source code in **contract.c**, which must be included for using this function.  

## *Parameters:* 

## Code  The Google or Quandl code, f.i. "NYSE:AMZN" or "WIKI/AAPL". For selecting a ticker from

a colon and the ticker symbol, f.i. **"ZACKS/ES:AAPL"**. The file is stored in the **Histor**

with **": /'** characters replaced with **"- \_"**, plus **"1"** when only the most recent record w

## Mode  FROM\_GOOGLE for downloading a time series from Google™ 

## FROM\_GOOGLE|1 for downloading only the last records, for live trading 

## FROM\_QUANDL for downloading a time series from Quandl™ (Zorro S and Quandl ke FROM\_QUANDL|1 for downloading only the most recent record, for live trading FROM\_QTABLE for downloading a Quandl™ data table 

## Period  Minimum time in minutes to keep the last downloaded file until a newer file is downloaded, 

the file. 

## Handle  A number from 1...1000 that identifies the dataset. Handles above 1000 are reserved for Z FileNa Name of the file, with relative or absolute path. 

## me 

## Record Number of records in the dataset. 

## s 

## Fields  Number of fields per record, including the date field. 

## Date  Timestamp in Windows DATE format. Days are represented by whole number increments 

1899, midnight UTC. The time of the day is represented in the fractional part of the n

## Start,  The first record and the number of records to be stored. 

## Num 

## Row,  The record and field number, starting with 0. The date is always the first field of the record. If Colum record is taken from the end of the file, i.e. Row = -1 accesses the oldest record. 

## n 

## Value  New value of the addressed field. 

## Filter  Filter string to select lines to be parsed. The line must contain the string. Use delimite

Use **'\n'** as first character when the line must begin with the filter string. 

## Format  CSV format string for parsing records with mixed content from a CSV file to a dataset, or for

the CSV format. Fields in the format string are separated with the same delimiter as in the semicolon, or '|' for a tab. A field can be either empty, or contain a placeholder that d

with no placeholder are skipped and don't appear in the dataset. A record of a CSV time s one date/time field; if there are more, f.i. separate fields for date and time, they are summed

Codes at the begin of the format string: 

## + - ascending date order; append records to the end of the dataset. Otherwise descending records are appended to the begin. 0,1,2 - number of header lines in the .csv file to be ski (default: 1). u01..u99 - skip all lines that are up to the nth character (n = 00..99) identical for storing only records with unique date/time fields. n - skip all lines that contain th

an invalid date/time field. 

The following placeholders can be used to parse field content. If the format string is empt the CSV file is parsed as if all fields contained floating point numbers. 

## f - for a floating point field, f.i. 123.456. If the delimiter is a semicolon, the decimal point can integer field. Nonnumerical characters are skipped, f.i. "07/21/16" is parsed to 72116

field. **ss... -** for an extended text field of size **4*n*-1**, where ***n*** is the number of '**s**'. Occupies dataset, while field 0 counts as 2 fields. **%t** - for a date/time field in Unix format, either sec January 1,1970. **%w** - for a date/time field in Windows **DATE** format, number of da 30,1899. **%...** - for a date/time field with **DATE** format codes, f.i. **"%Y-%m-%dT%H:** format. Trailing seconds can have decimals and are parsed with 1 microsecond prec

profit-and-loss curve generated by a backtest is a list of CSV records with a date and the as like **"2016-06-01,123.45"**, in ascending date order with a single header line. The format strin it to a dataset in T1 format. 

Date/time fields are parsed into field 0 of the dataset and can be retrieved with **dataVar(..,.** format. The number of fields in the dataset is the date field plus the sum of all **f**, **i**, **s** chara can be different to the number of fields in the CSV record. The **f**, **i**, **s** placeholders can be f number in the resulting dataset. Example: **"+%Y%m%d %H%M%S,f3,f1,f2,f4,f6"** parses dataset in **T6** format. **f0** parses the value into field 0, for datasets with no date field. I

fields are parsed in ascending order. Skipped fields are filled with 0.    

## Format  JSON format string containing the token names of a OHLC candle or  ask/bid (BBO)

candles are stored in T6 records, ask or bid quotes are stored in T2 records. 

T6: **"Start,Time,Timeformat,High,Low,Open,Close,AdjClose,Volume"** 

T2: **"Start,Time,Timeformat,Ask,AskSize,Bid,BidSize"** 

## Start - token name or start string of the whole price structure. Determines from wher Timeformat - format of the date/time field with DATE format codes, as in the CSV fo Time - token name of the date/time field. 

## High,Low,Open,Close - token names of the price fields. 

## AdjClose - token name of the adjusted close field, or empty if the file contains no such fiel Volume - toke name of the volume field, or empty if the file contains no volume data.

## Ask - token name of the best ask quote field. 

## AskSize - token name of the ask size field. 

## Bid - token name of the best bid quote field, or empty if the file contains no bid quotes. BidSize - token name of the bid size field, or empty. 

If the file already begins with the **'['** character, use it for the start token. Example: **"[,date,%t,high,low,open,close,,".** 

## *Remarks:* 

An easy way to generate the **Format** string is copying a line from the CSV file to the script as a format template, then editing its fields. Replace the year number with **%Y**, the month with **%m**, the day with **%d**, the hour with **%H**, the minute with **%M**, the second with **%S**. Replace prices with **f**, integer numbers or expiration dates with **i**, and text with **s**, **ss**, or **sss**,, dependent on the maximum string length. Delete the content of unused fields, but leave the delimiters. Add numbers to the placeholders when their fields in the target dataset are in a different order than in the CSV file (the header file **trading.h** contains the field numbers for often used structs). For instance, in a dataset in **T6** format, the Open is the third price (**f3**), High is first (**f1**), Low is second (**f2**), Close is 4th (**f4**), and Volume is sixth (**f6**). Finally, append **+**, **0**, or **2** to the begin of the resulting string dependent on date order and number of header lines. Now you have the correct **Format** string for parsing the file. 

` `For checking the correct parsing, set **Verbose** to **7**. The first two lines of the first CSV file are then printed to the log and message window, and their parsed versions below them. If your format string is so wrong that nothing is parsed at all, you'll get **Error 058** instead. For checking the correct parsing further, the resulting dataset can be saved to a CSV file with **dataSaveCSV**. 

For parsing extremely large CSV files, set **Verbose** to **2** or above. Zorro will then print a dot for every 1,000,000 parsed lines. If the resulting dataset does not fit in 32-bit memory, use the 64-bit Zorro version and 

a **.cpp** file for parsing. 

If you cannot determine the correct format string for parsing a complex file, Zorro support can help. For a fistful of EUR you can also order a conversion script (check out the **support page** under 

"Services"). Many example scripts for data parsing and conversion can also be found under **Import**. 

Numbers in CSV files must not exceed the **float range**. Only straight decimal numbers can be imported. Hex, binary, octal, or scientific notation with appended exponent is not supported. 

If **dataDownload** failed due to a wrong code or for other reasons, the target file usually contains the error message from the service. 

The **historical data files** are simply datasets with 2, 7, or 9 fields in descending timestamp order. They all can be loaded with **dataLoad**.. The record format is defined in **include\trading.h**. 

Converting exotic CSV files to a specific dataset format, such 

as **.t6** or **.t8**, requires often a 2-step process. In the first step, the CSV file is parsed into a temporary dataset. In the second step, the dataset is converted with a script that loops through all records and modifies fields to their final format. Examples of this can be found in the conversion **scripts**. 

When loading indicators from EOD data, be aware that the time stamp is usually from the begin of the day (00:00), while the data is from the end of the day (16:00). For avoiding future peeking, shift 

the **dataFind** time back by 16 hours, or use a 16\*60 minutes offset 

with **dataFromCSV**. 

For loading data from Quandl (Zorro S required), register 

on **www.quandl.com** and enter your received Quandl API key in 

the **Zorro.ini** file. 

For speed reasons, full historical data arrays should be only loaded in the initial run of the system. While live trading, 

use **FROM\_QUANDL|1** or **FROM\_GOOGLE|1** for downloading the most recent data record only (see example). 

The size of a record in bytes is **(Fields+1)\*4.** The size of the whole data area is therefore **Records\*(Fields+1)\*4**. Field 0 with the timestamp has a size of 8 bytes, the other fields have a size of 4 bytes. The number of records can be determined with **dataFind(Handle,0)**. 

For storing complex data such as structs, use a sufficient record size plus 8 bytes for the timestamp, and copy the struct 

to **dataStr(Handle,Record,1)**. If a separate timestamp is not needed, or if it is part of the struct as for the **T1**..**T8** structs, the struct can be stored 

to **dataStr(Handle,Record,0)**. 

For selecting a dataset not with its handle number, but with a string - for instance an asset name - use the **stridx / strxid** functions. 

For splitting extremely large CSV files into smaller parts, use free tools such as **CSVSplitter for Windows**. 

## *Examples (see also import, scripts, and contract):* 

## *// COT report for S&P500* 

## var CFTC\_SP(int Column) {  

`  `**return dataFromQuandl(802,"%Y-%m-%d,f,f,f,f,f,f,f,f,f,f,f,f,f,f,f, f,f","CFTC/TIFF\_CME\_SP\_ALL",Column);**  

## } 

## *// convert some .csv formats to .t6* 

## string Format = "%Y-%m-%d,f3,f1,f2,f4,,,f6,f5"; *// Quandl futures format to .t6, f.i. "CHRIS/CME\_CL1"* dataParse(1,Format,"History\\CL1.csv"); dataSave(1,"History\\CL1.t6"); 

## string Format = "%Y-%m-%d,f3,f1,f2,f4,f6,f5"; *// Yahoo data format to unadjusted .t6, with adjusted close stored in fVal* dataParse(1,Format,"History\\history.csv"); dataSave(1,"History\\AAPL.t6"); ![](Aspose.Words.e50cbba2-c5a5-4c94-8250-4a2b307dae06.001.png)

## *// read a time series out of field 1 of dataset H* 

## vars MyData = series(dataVar(H,dataFind(H,wdate(0)),1)); 

## *// Coinbase Bitcoin/EUR price to .t1* 

## void main() 

## { 

`  `**string Format = "+0,,,%t,f,f,s";** 

`  `**int Records = dataParse(1,Format,"History\\BTCEUR.csv");   printf("\n%d records read",Records);** 

## *// now convert it to t1 and change sign for sell quotes* 

`  `**for(i=0; i<Records; i++) {** 

`    `**T1\* t1 = dataAppendRow(2,2);** 

`    `**t1->time = dataVar(1,i,0);** 

`    `**t1->fVal = dataVar(1,i,1);** 

`    `**string sell = dataStr(1,i,3);** 

`    `**if(sell[0] == 't') t1->fVal = -t1->fVal;** 

## *// display progress bar and check [Stop] button* 

`    `**if(!progress(100\*i/Records,0)) break;** 

`  `**}** 

`  `**if(Records) dataSave(2,"History\\BTCEUR.t1");** 

## } 

## *// evaluate an extra parameter stored with time stamps in a dataset* 

## ... 

## if(Init) dataLoad(1,"History\\MyParameters.dta",2); 

## int Row = dataFind(1,wdate(0)); 

## MyExtraParameter = dataVar(1,Row,1); 

## ... 

## *// Download earnings data from AlphaVantage*  

## *// and store earnings surprises in a dataset* 

## int loadEarnings() 

## { 

`  `**string URL = strf("https://www.alphavantage.co/query?function=EARNINGS&s ymbol=%s&apikey=%s",** 

`    `**Asset,report(33));  *// 33 = AlphaVantage API key*** 

`  `**string Content = http\_transfer(URL,0); *// JSON format*** 

`  `**if(!Content) return 0;**  

`  `**string Pos = strstr(Content,"reportedDate");**   

`  `**if(!Pos) return 0;** 

`  `**dataNew(1,0,0);** 

`  `**while(Pos) {** 

`    `**var Date = wdatef("%Y-%m-%d",Pos+12+4);** 

`    `**if(Date == 0) break;** 

`    `**Pos = strstr(Pos,"surprisePercentage");** 

`    `**if(!Pos) break;** 

`    `**int Row = dataRow(1,dataAppendRow(1,2));** 

`    `**dataSet(1,Row,0,Date); *// earnings date in field 0*** 

`    `**dataSet(1,Row,1,atof(Pos+18+4)); *// surprise in field 1*     printf("\n%.4f %.4f",dataVar(1,Row,0),dataVar(1,Row,1));     Pos = strstr(Pos,"reportedDate"); *// next JSON record*** 

`  `**}** 

`  `**return 1;** 

## } 

## *// plot a heatmap* 

## void main() 

## { 

`  `**dataNew(1,8,10);** 

`  `**int i,j;** 

`  `**for(i=0; i<8; i++)**  

`    `**for(j=0; j<10; j++)** 

`      `**dataSet(1,i,j,(var)(i+j));** 

`  `**dataChart(1,"Test",HEATMAP,NULL); }** 

## *// plot a contour map* void main() 

## { 

`  `**dataNew(1,100,3);   int i,j;** 

`  `**for(i=0; i<10; i++)**  

`    `**for(j=0; j<10; j++) {** 

`      `**dataSet(1,i\*10+j,2,(var)i);** 

`      `**dataSet(1,i\*10+j,1,(var)j);** 

`      `**dataSet(1,i\*10+j,0,(var)(i+j));** 

`   `**}** 

`   `**dataChart(1,"Test",CONTOUR|DOT,NULL); }** 
